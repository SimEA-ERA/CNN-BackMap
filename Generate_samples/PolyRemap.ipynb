{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d9d37bf",
   "metadata": {},
   "source": [
    "# Workflow for the Backmapping method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0104ff",
   "metadata": {},
   "source": [
    "![title](./bcml.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60021f18",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ca7b6f",
   "metadata": {},
   "source": [
    "* <a href='#a'> Import the needed libraries for the task </a>\n",
    "* <a href='#pre-processing'> Pre-processing \n",
    "    - <a href='#c'> Load the chemical structure of the system </a>\n",
    "    - <a href='#d'> Load the trajectory file </a>\n",
    "    - <a href='#e'> Compute the number of particles per chain  </a>\n",
    "    - <a href='#g'> Compute the bond vectors for each monomer type  </a>\n",
    "    - <a href='#h'> Define the function that generates the target and input of the CNN  </a>\n",
    "    - <a href='#f'> Create CNN input and target output for a test-set configuration  </a>\n",
    "* <a href='#training-process'> Backmapping by utilizing the trained CNN    \n",
    "   * <a href='#j'> Load the data </a>\n",
    "   * <a href='#i'> Develop the conditional convolutional neural network  </a>\n",
    "   * <a href='#l'> Decoding process  </a>\n",
    "    - <a href='#m'> Decoding the output of the neural network for each CG type </a>\n",
    "    - <a href='#n'> Get the structure of each chain </a>\n",
    "    - <a href='#o'> Re-insert atomic detail to CG congigurations via the trained CNN </a>\n",
    "   * <a href='#p'> Prediction of an atomistic configuration from a given CG configuration  </a> \n",
    "* <a href='#q'> Visualize the results </a>\n",
    "    - <a href='#r'> Generate the distribution plots for bond lengths, bond angles and dihedral angles </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad4f90",
   "metadata": {},
   "source": [
    "# Import the needed libraries for this task  <span id='a'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0872ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import mdtraj as md\n",
    "from copo import load_chemistry\n",
    "from params import *\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from distribution_plots import generate_distribution_plots\n",
    "# turn off the warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1773e5c",
   "metadata": {},
   "source": [
    "# Pre-processing <span id='pre-processing'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bfb733",
   "metadata": {},
   "source": [
    "### Load the chemical structure of the system <span id='c'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5535eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 96 molecules\n",
      "Number of Chains per configuration: 96\n",
      "Number of Monomers per chain: 30\n"
     ]
    }
   ],
   "source": [
    "chemistry_filename = '../Data/chem_tcv_451045.txt'\n",
    "chemistry, chemistry_names = load_chemistry(chemistry_filename, None)\n",
    "chemistry = np.array(chemistry)\n",
    "print(\"Number of Chains per configuration:\",chemistry.shape[0])\n",
    "print(\"Number of Monomers per chain:\",chemistry.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23737d70",
   "metadata": {},
   "source": [
    "### Load the trajectory file <span id='d'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6490ce7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mdtraj.Trajectory with 1851 frames, 11562 atoms, 96 residues, and unitcells>\n"
     ]
    }
   ],
   "source": [
    "t = md.load('../Data/trajout_long.gro')\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942639fd",
   "metadata": {},
   "source": [
    "###  Compute the number of particles per chain  <span id='e'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7cc68f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_chainlens(chemistry,merlen_cis,merlen_trans,merlen_vinyl):\n",
    "    chainlens = []\n",
    "    for i in range(chemistry.shape[0]):\n",
    "      ntypes = [np.count_nonzero(chemistry[i] == 0),np.count_nonzero(chemistry[i] == 1),np.count_nonzero(chemistry[i] == 2)] \n",
    "      chainlen = ntypes[0]*merlen_cis + ntypes[1]*merlen_trans + ntypes[2]*merlen_vinyl\n",
    "      chainlens.append(int(chainlen))\n",
    "    \n",
    "    chainlens = np.array(chainlens, dtype=np.uint8)\n",
    "    np.savetxt(\"./chainlens.txt\",chainlens)\n",
    "    return chainlens  \n",
    "\n",
    "chainlens = calc_chainlens(chemistry,merlen_cis,merlen_trans,merlen_vinyl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ec906b",
   "metadata": {},
   "source": [
    "### Compute the bond vectors for each monomer type  <span id='g'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b5d7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cis_vectors(index,imageAT,Coord,jj,b0):\n",
    "    bv1=Coord[1+index]-Coord[index]\n",
    "    bv2=Coord[2+index]-Coord[1+index]\n",
    "    bv3=Coord[3+index]-Coord[2+index]\n",
    "    if jj != nmer-1:\n",
    "      bv0=Coord[4+index]-Coord[3+index]\n",
    "    else:\n",
    "      bv0= b0[:]\n",
    "    imageAT.append([bv1[0],bv1[1],bv1[2]])\n",
    "    imageAT.append([bv2[0],bv2[1],bv2[2]])\n",
    "    imageAT.append([bv3[0],bv3[1],bv3[2]])      \n",
    "    imageAT.append([bv0[0],bv0[1],bv0[2]])\n",
    "    return bv0     \n",
    "\n",
    "def trans_vectors(index,imageAT,Coord,jj,b0):\n",
    "    bv1=Coord[1+index]-Coord[index]\n",
    "    bv2=Coord[2+index]-Coord[1+index]\n",
    "    bv3=Coord[3+index]-Coord[2+index]\n",
    "    if jj != nmer-1:\n",
    "      bv0=Coord[4+index]-Coord[3+index]\n",
    "    else:\n",
    "      bv0= b0[:]\n",
    "    imageAT.append([bv1[0],bv1[1],bv1[2]])\n",
    "    imageAT.append([bv2[0],bv2[1],bv2[2]])\n",
    "    imageAT.append([bv3[0],bv3[1],bv3[2]])      \n",
    "    imageAT.append([bv0[0],bv0[1],bv0[2]])\n",
    "    return bv0     \n",
    "\n",
    "def vinyl_vectors(index,imageAT,Coord,jj,b0):\n",
    "    bv1=Coord[1+index]-Coord[index]\n",
    "    bv2=Coord[2+index]-Coord[1+index]\n",
    "    bv3=Coord[3+index]-Coord[2+index]\n",
    "    if jj != nmer-1:\n",
    "      bv0=Coord[4+index]-Coord[1+index]\n",
    "    else:\n",
    "      bv0= b0[:]    \n",
    "    imageAT.append([bv1[0],bv1[1],bv1[2]])\n",
    "    imageAT.append([bv2[0],bv2[1],bv2[2]])\n",
    "    imageAT.append([bv3[0],bv3[1],bv3[2]])      \n",
    "    imageAT.append([bv0[0],bv0[1],bv0[2]])\n",
    "    return bv0     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe2dbf",
   "metadata": {},
   "source": [
    "### Define the function that generates the target and input of the CNN <span id='h'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63c41b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(frames,save_path,t,chemistry):  \n",
    " input_file=[]\n",
    " target_file=[]  \n",
    " b0 = np.zeros((3))\n",
    " for frameIndx in frames:\n",
    "    # Counter to ignore the last particle of the chain, when the chain ends in vinly-1,2\n",
    "    counter=0\n",
    "    \n",
    "    # Compute the length of the box\n",
    "    LXX,LYY,LZZ=t.unitcell_lengths[frameIndx][0],t.unitcell_lengths[frameIndx][1],t.unitcell_lengths[frameIndx][2]\n",
    "    \n",
    "    hLXX,hLYY,hLZZ=LXX/2.0,LYY/2.0,LZZ/2.0\n",
    "    Coord=np.zeros([npart,3],dtype=np.float32)\n",
    "    \n",
    "    # Counter for the particles of the frame\n",
    "    frame_counter_1 = -1\n",
    "    \n",
    "    frame_counter_2 = 0\n",
    "    for j in range(nchain):\n",
    "        coordCG=np.zeros([nmer,3],dtype=np.float32)\n",
    "        coordAT = []  \n",
    "        for jj in range(nmer):\n",
    "            # Compute the type of the monomer\n",
    "            type = chemistry[j][jj]\n",
    "            \n",
    "            posCM=[0.,0.,0.]\n",
    "            if(type==0): masses,merlen = masses_cis,merlen_cis\n",
    "            elif(type==1): masses,merlen = masses_trans,merlen_trans\n",
    "            elif(type==2): masses,merlen = masses_vinyl,merlen_vinyl\n",
    "            totmass=np.sum(masses)\n",
    "            for ii in range(merlen):\n",
    "                frame_counter_1 += 1\n",
    "                partIndx = frame_counter_1\n",
    "                \n",
    "                # Compute the un-wrapped coordinates of the particles\n",
    "                Coord[partIndx]=t.xyz[frameIndx,(partIndx+counter),:]\n",
    "                if (jj!=0 or ii!=0):\n",
    "                    if(Coord[partIndx][0]-Coord[partIndx-1][0]<-hLXX): Coord[partIndx][0]+=LXX\n",
    "                    if(Coord[partIndx][0]-Coord[partIndx-1][0]>hLXX): Coord[partIndx][0]-=LXX\n",
    "                    if(Coord[partIndx][1]-Coord[partIndx-1][1]<-hLYY): Coord[partIndx][1]+=LYY\n",
    "                    if(Coord[partIndx][1]-Coord[partIndx-1][1]>hLYY): Coord[partIndx][1]-=LYY\n",
    "                    if(Coord[partIndx][2]-Coord[partIndx-1][2]<-hLZZ): Coord[partIndx][2]+=LZZ\n",
    "                    if(Coord[partIndx][2]-Coord[partIndx-1][2]>hLZZ): Coord[partIndx][2]-=LZZ\n",
    "           \n",
    "            # Compute the coordinates of the CG particles of the chain \n",
    "                posCM[0]+=Coord[partIndx][0]*masses[ii]\n",
    "                posCM[1]+=Coord[partIndx][1]*masses[ii]\n",
    "                posCM[2]+=Coord[partIndx][2]*masses[ii]\n",
    "\n",
    "            posCM[0]/=totmass\n",
    "            posCM[1]/=totmass\n",
    "            posCM[2]/=totmass\n",
    "            # Save the coordinates of the CG particles of the chain \n",
    "            coordCG[jj]=posCM[:]\n",
    "            \n",
    "        # Ignore the last particle of the chain, when the chain ends in vinyl-1,2    \n",
    "        if(j in cv3): counter+=1\n",
    "        \n",
    "        for jj in range(nmer):\n",
    "            type = chemistry[j][jj]\n",
    "            \n",
    "            # Compute the bond vectors for each monomer \n",
    "            if(type==0):\n",
    "                merlen = merlen_cis\n",
    "                b0[:]=cis_vectors(frame_counter_2,coordAT,Coord,jj,b0)\n",
    "            elif(type==1): \n",
    "                merlen = merlen_trans\n",
    "                b0[:]=trans_vectors(frame_counter_2,coordAT,Coord,jj,b0)\n",
    "            elif(type==2):\n",
    "                merlen = merlen_vinyl  \n",
    "                b0[:]=vinyl_vectors(frame_counter_2,coordAT,Coord,jj,b0)\n",
    "\n",
    "            frame_counter_2 += merlen\n",
    "\n",
    "        coordAT = np.array(coordAT,dtype=np.float64)                \n",
    "        \n",
    "        # Compute the number of splits (samples) per chain \n",
    "        nsplits = int(np.ceil((coordAT.shape[0])/INPUT_WIDTH))  \n",
    "        s = int(np.ceil(nmer/nsplits)) \n",
    "        if (s*(4)) > INPUT_WIDTH: nsplits += 1\n",
    "        s = int(np.ceil(nmer/nsplits))\n",
    "        meridx = [(s*(h+1)-1) for h in range(nsplits)]\n",
    "        meridx.pop(-1)\n",
    "        meridx.append(nmer-1)\n",
    "        AT = []\n",
    "        CG = []\n",
    "        frame_counter = -1\n",
    "        arrAT = np.zeros([INPUT_WIDTH,3],dtype=np.float64)\n",
    "        arrCG = np.zeros([INPUT_WIDTH,6],dtype=np.float64)\n",
    "        for jj in range(nmer):\n",
    "            type = chemistry[j][jj]\n",
    "            if(type==0): \n",
    "                dtseg = dtseg_cis\n",
    "                m_id = [0,0,1]\n",
    "            elif(type==1):\n",
    "                dtseg = dtseg_trans\n",
    "                m_id = [0,1,0]\n",
    "            elif(type==2): \n",
    "                dtseg = dtseg_vinyl\n",
    "                m_id = [1,0,0]\n",
    "            for g in range(dtseg):\n",
    "                frame_counter += 1\n",
    "        \n",
    "                AT.append([coordAT[frame_counter][0],coordAT[frame_counter][1],coordAT[frame_counter][2]])\n",
    "                CG.append([coordCG[jj][0],coordCG[jj][1],coordCG[jj][2],m_id[0],m_id[1],m_id[2]])\n",
    "            \n",
    "            # Create input and target samples \n",
    "            if jj in meridx: \n",
    "                AT = np.array(AT,dtype=np.float64)\n",
    "                CG = np.array(CG,dtype=np.float64)\n",
    "                \n",
    "                # Compute the zero-padding \n",
    "                shiftx = int(np.ceil((INPUT_WIDTH - AT.shape[0])/2))\n",
    "                \n",
    "                arrAT[shiftx:shiftx+int(AT.shape[0])] = AT[:]\n",
    "                arrCG[shiftx:shiftx+int(CG.shape[0])] = CG[:]  \n",
    "                input_file.append(arrCG)\n",
    "                target_file.append(arrAT)                \n",
    "                AT = []\n",
    "                CG = []\n",
    "                arrAT = np.zeros([INPUT_WIDTH,3],dtype=np.float64)\n",
    "                arrCG = np.zeros([INPUT_WIDTH,6],dtype=np.float64)\n",
    "                \n",
    " final_input=np.array(input_file,dtype=np.float64)\n",
    " final_target=np.array(target_file,dtype=np.float64) \n",
    " print(\"Input shape:\", final_input.shape)\n",
    " print(\"Target output shape:\", final_target.shape)      \n",
    " \n",
    " with open(save_path+'_input.pkl','wb') as f:\n",
    "     pickle.dump(final_input, f)\n",
    "\n",
    " with open(save_path+'_target.pkl','wb') as f:\n",
    "     pickle.dump(final_target, f)        \n",
    " input_file = []\n",
    " target_file = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4a2227",
   "metadata": {},
   "source": [
    "### Create CNN inputs and target outputs for a test-set configuration <span id='f'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "150d7eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (96, 128, 6)\n",
      "Target output shape: (96, 128, 3)\n",
      "Create CNN input and target output for configuration: 525\n"
     ]
    }
   ],
   "source": [
    "random.seed(100)\n",
    "frames = random.sample(range(1851), 1851)\n",
    "\n",
    "# Configurations of the test-set\n",
    "test_frames = frames[1666:]\n",
    "\n",
    "# Choose a configuration of the test-set\n",
    "save_path=\"test\" \n",
    "encoding([test_frames[0]],save_path,t,chemistry) \n",
    "\n",
    "test_frame = test_frames[0]\n",
    "\n",
    "print(\"Create CNN input and target output for configuration:\",test_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac82fd67",
   "metadata": {},
   "source": [
    "# Backmapping by utilizing the trained CNN   <span id='training-process'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b105cb9",
   "metadata": {},
   "source": [
    "### Load the data <span id='j'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8450969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of target output for a single configuration: (96, 128, 3)\n",
      "Shape of input for a single configuration: (96, 128, 6)\n",
      "Number of samples: 96\n"
     ]
    }
   ],
   "source": [
    "with open('./test_target.pkl','rb') as f:\n",
    "    test_target = pickle.load(f)\n",
    "    print(\"Shape of target output for a single configuration:\",test_target.shape)    \n",
    "\n",
    "with open('./test_input.pkl','rb') as f:\n",
    "    test_input = pickle.load(f)\n",
    "    print(\"Shape of input for a single configuration:\",test_input.shape)        \n",
    "\n",
    "print(\"Number of samples:\",test_input.shape[0])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ad1e56",
   "metadata": {},
   "source": [
    "### Develop the conditional convolutional neural network  <span id='i'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c6827d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "# Downsample blog\n",
    "def downsample(entered_input,filters, size, apply_batchnorm=True,strides=2):\n",
    "  \n",
    "  conv1 = tf.keras.layers.Conv1D(filters, size, strides=strides, padding='same',use_bias=False)(entered_input) \n",
    "  conv1 = tf.keras.layers.LeakyReLU()(conv1)\n",
    "  \n",
    "  if apply_batchnorm:\n",
    "    conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "\n",
    "  return conv1\n",
    "\n",
    "# Upsample blog\n",
    "def upsample(entered_input,filters, size, skip_layer, apply_dropout=False, strides=2, apply_skip=True):\n",
    "  tran1 = tf.keras.layers.Conv1DTranspose(filters, size, strides=strides, padding='same', use_bias=True)(entered_input)\n",
    "  tran1 = tf.keras.layers.ReLU()(tran1) \n",
    "  if apply_dropout:\n",
    "      tran1 = tf.keras.layers.Dropout(0.5)(tran1)\n",
    "  \n",
    "  if apply_skip:\n",
    "      tran1 = tf.keras.layers.Concatenate()([tran1,skip_layer])\n",
    "  return tran1\n",
    "\n",
    "# Create the Convolutional Neural Network (CNN)\n",
    "def Generator(input_size): \n",
    "  input1 = tf.keras.layers.Input(input_size)  \n",
    "  output1 = downsample(input1, 64, 3)\n",
    "  output2 = downsample(output1, 128, 3)\n",
    "  output3 = downsample(output2, 256, 3)  \n",
    "  output4 = downsample(output3, 512, 3) \n",
    "  output5 = downsample(output4, 512, 3) \n",
    "  \n",
    "  output = upsample(output5, 512, 3, output4, apply_dropout=True)\n",
    "  output = upsample(output, 256, 3, output3, apply_dropout=False)\n",
    "  output = upsample(output, 128, 3, output2, apply_dropout=False)\n",
    "  output = upsample(output, 64, 3, output1, apply_dropout=False)\n",
    "  \n",
    "  output = tf.keras.layers.Conv1DTranspose(64, 3, strides=2, padding=\"same\",  activation=\"relu\")(output)\n",
    "  out = tf.keras.layers.Conv1DTranspose(3, 3, strides=1, padding=\"same\",  activation=\"tanh\")(output)\n",
    "\n",
    "  model = tf.keras.models.Model(input1,out)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf9e5d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 128, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 64, 64)       1152        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 64, 64)       0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64)       256         leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 32, 128)      24576       batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 32, 128)      0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 128)      512         leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 16, 256)      98304       batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 16, 256)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 256)      1024        leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 8, 512)       393216      batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 8, 512)       0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 512)       2048        leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 4, 512)       786432      batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 4, 512)       0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 4, 512)       2048        leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_18 (Conv1DTran (None, 8, 512)       786944      batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 8, 512)       0           conv1d_transpose_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 8, 512)       0           re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 8, 1024)      0           dropout_3[0][0]                  \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_19 (Conv1DTran (None, 16, 256)      786688      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 16, 256)      0           conv1d_transpose_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 512)      0           re_lu_13[0][0]                   \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_20 (Conv1DTran (None, 32, 128)      196736      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 32, 128)      0           conv1d_transpose_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 32, 256)      0           re_lu_14[0][0]                   \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_21 (Conv1DTran (None, 64, 64)       49216       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 64, 64)       0           conv1d_transpose_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 64, 128)      0           re_lu_15[0][0]                   \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_22 (Conv1DTran (None, 128, 64)      24640       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_23 (Conv1DTran (None, 128, 3)       579         conv1d_transpose_22[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 3,154,371\n",
      "Trainable params: 3,151,427\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (INPUT_WIDTH,6)\n",
    "\n",
    "model = Generator(input_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faad728",
   "metadata": {},
   "source": [
    "# Decoding process <span id='l'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ebe52",
   "metadata": {},
   "source": [
    "### Decoding the output of the neural network for each CG type <span id='m'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22659928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cis_d(pos,masses,iosx,iosy,iosz,b0,nmer_count,Coords,identities,PartIndx):          \n",
    "     b1 = [pos[0,0],pos[0,1],pos[0,2]]\n",
    "     b2 = [pos[1,0],pos[1,1],pos[1,2]]\n",
    "     b3 = [pos[2,0],pos[2,1],pos[2,2]]\n",
    "     b0[nmer_count][:] = [pos[3,0],pos[3,1],pos[3,2]]\n",
    "     vcoords = np.zeros((5,3))\n",
    "     totmass = np.sum(masses)\n",
    "     if nmer_count == 0:  \n",
    "       posx=-(masses[1]*b1[0]+masses[2]*(b1[0]+b2[0])+masses[3]*(b1[0]+b2[0]+b3[0]))/totmass\n",
    "       posy=-(masses[1]*b1[1]+masses[2]*(b1[1]+b2[1])+masses[3]*(b1[1]+b2[1]+b3[1]))/totmass\n",
    "       posz=-(masses[1]*b1[2]+masses[2]*(b1[2]+b2[2])+masses[3]*(b1[2]+b2[2]+b3[2]))/totmass\n",
    "      \n",
    "       vcoords[1][:] = [posx,posy,posz]\n",
    "       vcoords[2][:] = [vcoords[1][0]+b1[0],vcoords[1][1]+b1[1],vcoords[1][2]+b1[2]]     \n",
    "       vcoords[3][:] = [vcoords[2][0]+b2[0],vcoords[2][1]+b2[1],vcoords[2][2]+b2[2]]    \n",
    "       vcoords[4][:] = [vcoords[3][0]+b3[0],vcoords[3][1]+b3[1],vcoords[3][2]+b3[2]]      \n",
    "     \n",
    "     elif nmer_count != 0: \n",
    "       posx=-(b0[nmer_count-1][0]*masses[0]+masses[1]*(b0[nmer_count-1][0]+b1[0])+masses[2]*(b0[nmer_count-1][0]+b1[0]+b2[0])+masses[3]*(b0[nmer_count-1][0]+b1[0]+b2[0]+b3[0]))/totmass\n",
    "       posy=-(b0[nmer_count-1][1]*masses[0]+masses[1]*(b0[nmer_count-1][1]+b1[1])+masses[2]*(b0[nmer_count-1][1]+b1[1]+b2[1])+masses[3]*(b0[nmer_count-1][1]+b1[1]+b2[1]+b3[1]))/totmass\n",
    "       posz=-(b0[nmer_count-1][2]*masses[0]+masses[1]*(b0[nmer_count-1][2]+b1[2])+masses[2]*(b0[nmer_count-1][2]+b1[2]+b2[2])+masses[3]*(b0[nmer_count-1][2]+b1[2]+b2[2]+b3[2]))/totmass  \n",
    "       \n",
    "       vcoords[0][:] = [posx,posy,posz]\n",
    "       vcoords[1][:] = [vcoords[0][0]+b0[nmer_count-1][0],vcoords[0][1]+b0[nmer_count-1][1],vcoords[0][2]+b0[nmer_count-1][2]]   \n",
    "       vcoords[2][:] = [vcoords[1][0]+b1[0],vcoords[1][1]+b1[1],vcoords[1][2]+b1[2]]  \n",
    "       vcoords[3][:] = [vcoords[2][0]+b2[0],vcoords[2][1]+b2[1],vcoords[2][2]+b2[2]]  \n",
    "       vcoords[4][:] = [vcoords[3][0]+b3[0],vcoords[3][1]+b3[1],vcoords[3][2]+b3[2]]  \n",
    "         \n",
    "     Coords[PartIndx][:] = [iosx+vcoords[1][0],iosy+vcoords[1][1],iosz+vcoords[1][2]]\n",
    "     Coords[PartIndx+1][:] = [iosx+vcoords[2][0],iosy+vcoords[2][1],iosz+vcoords[2][2]]\n",
    "     Coords[PartIndx+2][:] = [iosx+vcoords[3][0],iosy+vcoords[3][1],iosz+vcoords[3][2]]\n",
    "     Coords[PartIndx+3][:] = [iosx+vcoords[4][0],iosy+vcoords[4][1],iosz+vcoords[4][2]]     \n",
    "\n",
    "     return \n",
    "\n",
    "def trans_d(pos,masses,iosx,iosy,iosz,b0,nmer_count,Coords,identities,PartIndx):  \n",
    "     b1 = [pos[0,0],pos[0,1],pos[0,2]]\n",
    "     b2 = [pos[1,0],pos[1,1],pos[1,2]]\n",
    "     b3 = [pos[2,0],pos[2,1],pos[2,2]]\n",
    "     b0[nmer_count][:] = [pos[3,0],pos[3,1],pos[3,2]]\n",
    "     vcoords = np.zeros((5,3))\n",
    "     totmass = np.sum(masses)\n",
    "     if nmer_count == 0:  \n",
    "       posx=-(masses[1]*b1[0]+masses[2]*(b1[0]+b2[0])+masses[3]*(b1[0]+b2[0]+b3[0]))/totmass\n",
    "       posy=-(masses[1]*b1[1]+masses[2]*(b1[1]+b2[1])+masses[3]*(b1[1]+b2[1]+b3[1]))/totmass\n",
    "       posz=-(masses[1]*b1[2]+masses[2]*(b1[2]+b2[2])+masses[3]*(b1[2]+b2[2]+b3[2]))/totmass\n",
    "      \n",
    "       vcoords[1][:] = [posx,posy,posz]\n",
    "       vcoords[2][:] = [vcoords[1][0]+b1[0],vcoords[1][1]+b1[1],vcoords[1][2]+b1[2]]     \n",
    "       vcoords[3][:] = [vcoords[2][0]+b2[0],vcoords[2][1]+b2[1],vcoords[2][2]+b2[2]]    \n",
    "       vcoords[4][:] = [vcoords[3][0]+b3[0],vcoords[3][1]+b3[1],vcoords[3][2]+b3[2]]\n",
    "     \n",
    "     elif nmer_count != 0: \n",
    "       posx=-(b0[nmer_count-1][0]*masses[0]+masses[1]*(b0[nmer_count-1][0]+b1[0])+masses[2]*(b0[nmer_count-1][0]+b1[0]+b2[0])+masses[3]*(b0[nmer_count-1][0]+b1[0]+b2[0]+b3[0]))/totmass\n",
    "       posy=-(b0[nmer_count-1][1]*masses[0]+masses[1]*(b0[nmer_count-1][1]+b1[1])+masses[2]*(b0[nmer_count-1][1]+b1[1]+b2[1])+masses[3]*(b0[nmer_count-1][1]+b1[1]+b2[1]+b3[1]))/totmass\n",
    "       posz=-(b0[nmer_count-1][2]*masses[0]+masses[1]*(b0[nmer_count-1][2]+b1[2])+masses[2]*(b0[nmer_count-1][2]+b1[2]+b2[2])+masses[3]*(b0[nmer_count-1][2]+b1[2]+b2[2]+b3[2]))/totmass  \n",
    "       \n",
    "       vcoords[0][:] = [posx,posy,posz]\n",
    "       vcoords[1][:] = [vcoords[0][0]+b0[nmer_count-1][0],vcoords[0][1]+b0[nmer_count-1][1],vcoords[0][2]+b0[nmer_count-1][2]]   \n",
    "       vcoords[2][:] = [vcoords[1][0]+b1[0],vcoords[1][1]+b1[1],vcoords[1][2]+b1[2]]  \n",
    "       vcoords[3][:] = [vcoords[2][0]+b2[0],vcoords[2][1]+b2[1],vcoords[2][2]+b2[2]]  \n",
    "       vcoords[4][:] = [vcoords[3][0]+b3[0],vcoords[3][1]+b3[1],vcoords[3][2]+b3[2]]  \n",
    "         \n",
    "     Coords[PartIndx][:] = [iosx+vcoords[1][0],iosy+vcoords[1][1],iosz+vcoords[1][2]]\n",
    "     Coords[PartIndx+1][:] = [iosx+vcoords[2][0],iosy+vcoords[2][1],iosz+vcoords[2][2]]\n",
    "     Coords[PartIndx+2][:] = [iosx+vcoords[3][0],iosy+vcoords[3][1],iosz+vcoords[3][2]]\n",
    "     Coords[PartIndx+3][:] = [iosx+vcoords[4][0],iosy+vcoords[4][1],iosz+vcoords[4][2]]     \n",
    "\n",
    "     return \n",
    "     \n",
    "def vinyl_d(pos,masses,iosx,iosy,iosz,b0,nmer_count,Coords,identities,PartIndx):  \n",
    "     b1 = [pos[0,0],pos[0,1],pos[0,2]]\n",
    "     b2 = [pos[1,0],pos[1,1],pos[1,2]]\n",
    "     b3 = [pos[2,0],pos[2,1],pos[2,2]]\n",
    "     b0[nmer_count][:] = [pos[3,0],pos[3,1],pos[3,2]]\n",
    "     vcoords = np.zeros((5,3))\n",
    "     totmass = np.sum(masses)\n",
    "     if nmer_count == 0:  \n",
    "       posx=-(masses[1]*b1[0]+masses[2]*(b1[0]+b2[0])+masses[3]*(b1[0]+b2[0]+b3[0]))/totmass\n",
    "       posy=-(masses[1]*b1[1]+masses[2]*(b1[1]+b2[1])+masses[3]*(b1[1]+b2[1]+b3[1]))/totmass\n",
    "       posz=-(masses[1]*b1[2]+masses[2]*(b1[2]+b2[2])+masses[3]*(b1[2]+b2[2]+b3[2]))/totmass\n",
    "      \n",
    "       vcoords[1][:] = [posx,posy,posz]\n",
    "       vcoords[2][:] = [vcoords[1][0]+b1[0],vcoords[1][1]+b1[1],vcoords[1][2]+b1[2]]     \n",
    "       vcoords[3][:] = [vcoords[2][0]+b2[0],vcoords[2][1]+b2[1],vcoords[2][2]+b2[2]]    \n",
    "       vcoords[4][:] = [vcoords[3][0]+b3[0],vcoords[3][1]+b3[1],vcoords[3][2]+b3[2]]\n",
    "       \n",
    "     elif nmer_count != 0: \n",
    "       posx=-(b0[nmer_count-1][0]*masses[0]+masses[1]*(b0[nmer_count-1][0]+b1[0])+masses[2]*(b0[nmer_count-1][0]+b1[0]+b2[0])+masses[3]*(b0[nmer_count-1][0]+b1[0]+b2[0]+b3[0]))/totmass\n",
    "       posy=-(b0[nmer_count-1][1]*masses[0]+masses[1]*(b0[nmer_count-1][1]+b1[1])+masses[2]*(b0[nmer_count-1][1]+b1[1]+b2[1])+masses[3]*(b0[nmer_count-1][1]+b1[1]+b2[1]+b3[1]))/totmass\n",
    "       posz=-(b0[nmer_count-1][2]*masses[0]+masses[1]*(b0[nmer_count-1][2]+b1[2])+masses[2]*(b0[nmer_count-1][2]+b1[2]+b2[2])+masses[3]*(b0[nmer_count-1][2]+b1[2]+b2[2]+b3[2]))/totmass  \n",
    "       \n",
    "       vcoords[0][:] = [posx,posy,posz]\n",
    "       vcoords[1][:] = [vcoords[0][0]+b0[nmer_count-1][0],vcoords[0][1]+b0[nmer_count-1][1],vcoords[0][2]+b0[nmer_count-1][2]]   \n",
    "       vcoords[2][:] = [vcoords[1][0]+b1[0],vcoords[1][1]+b1[1],vcoords[1][2]+b1[2]]  \n",
    "       vcoords[3][:] = [vcoords[2][0]+b2[0],vcoords[2][1]+b2[1],vcoords[2][2]+b2[2]]  \n",
    "       vcoords[4][:] = [vcoords[3][0]+b3[0],vcoords[3][1]+b3[1],vcoords[3][2]+b3[2]]  \n",
    "         \n",
    "     Coords[PartIndx][:] = [iosx+vcoords[1][0],iosy+vcoords[1][1],iosz+vcoords[1][2]]\n",
    "     Coords[PartIndx+1][:] = [iosx+vcoords[2][0],iosy+vcoords[2][1],iosz+vcoords[2][2]]\n",
    "     Coords[PartIndx+2][:] = [iosx+vcoords[3][0],iosy+vcoords[3][1],iosz+vcoords[3][2]]\n",
    "     Coords[PartIndx+3][:] = [iosx+vcoords[4][0],iosy+vcoords[4][1],iosz+vcoords[4][2]]     \n",
    "\n",
    "     return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6d64d3",
   "metadata": {},
   "source": [
    "### Get the structure of each chain <span id='n'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32e5ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mer_identity(inp):  \n",
    "  # Compute the zero-padding  \n",
    "  shiftx = [i for i, rgb in enumerate(inp) if rgb[0] != 0 and rgb[1] != 0 and rgb[2] != 0][0]   \n",
    "  identities = []\n",
    "  names = []\n",
    "  cis_names = [\"CC\",\"CDC\",\"CDC\",\"CC\"]\n",
    "  trans_names = [\"CT\",\"CDT\",\"CDT\",\"CT\"]\n",
    "  vinyl_names = [\"CV2\",\"CV1\",\"CDV1\",\"CDV2\"]   \n",
    "  f = 0\n",
    "  # Find the sequence of CG types\n",
    "  for i in range(inp.shape[0]):\n",
    "      if (inp[i,5]==1 and (abs(inp[i,0])+abs(inp[i,1])+abs(inp[i,2])) != 0) :\n",
    "          f += 1\n",
    "          if f%dtseg_cis != 0: \n",
    "              continue\n",
    "          else:    \n",
    "              identities.append(int(0))\n",
    "              names += cis_names\n",
    "      elif (inp[i,4]==1 and (abs(inp[i,0])+abs(inp[i,1])+abs(inp[i,2])) != 0):  \n",
    "          f += 1 \n",
    "          if f%dtseg_trans != 0: \n",
    "              continue\n",
    "          else:    \n",
    "              identities.append(int(1))\n",
    "              names += trans_names\n",
    "      elif (inp[i,3]==1 and (abs(inp[i,0])+abs(inp[i,1])+abs(inp[i,2])) != 0):  \n",
    "          f += 1 \n",
    "          if f%dtseg_vinyl != 0: \n",
    "              continue\n",
    "          else:\n",
    "              identities.append(int(2))\n",
    "              names += vinyl_names\n",
    "  # Compute the number of monomers in this sample            \n",
    "  img_nmer = len(identities)      \n",
    "  return identities, shiftx, img_nmer, names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e77e12a",
   "metadata": {},
   "source": [
    "### Re-insert atomic detail to CG congigurations via the trained CNN <span id='o'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d83a33bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ua_idx(shiftx,c,j):\n",
    "    return shiftx + c + j\n",
    "\n",
    "def create_chains(test_frame):\n",
    " # Length of the simulation box   \n",
    " LXX,LYY,LZZ= 6.73965 , 6.73965 , 6.73965 \n",
    " hLXX,hLYY,hLZZ=LXX/2.0,LYY/2.0,LZZ/2.0\n",
    " \n",
    " # Counter for the test-frames index\n",
    " nframes = 0\n",
    " \n",
    " # Number of particles per chain\n",
    " chainlens = np.loadtxt('./chainlens.txt')\n",
    " save_path=\"./Data/\"\n",
    " os.mkdir(save_path)\n",
    " pdimg=0\n",
    " chemistry = []\n",
    " chain_names = []\n",
    " nmer_count = 0\n",
    " PartIndx = 0\n",
    " pb0=np.zeros([nmer,3],dtype=np.float64)  \n",
    " tb0=np.zeros([nmer,3],dtype=np.float64)  \n",
    " for inp, tar in zip(test_input,test_target):\n",
    "  inp = np.reshape(inp,(1,INPUT_WIDTH,6))   \n",
    "  if len(chemistry) == 0:   \n",
    "    Pcoords = np.zeros([int(chainlens[pdimg]),3],dtype=np.float64)\n",
    "    Tcoords = np.zeros([int(chainlens[pdimg]),3],dtype=np.float64)\n",
    "    if pdimg == 0:\n",
    "     Pst = open(save_path+'PStart_'+str(test_frame)+'.gro', 'w')\n",
    "     Pst.write(\"PB_TCV_451045\\n\")\n",
    "     Pst.write(str(npart)+\"\\n\")\n",
    "    \n",
    "     pstd = open(save_path+\"PStart_\"+str(test_frame)+'.dat', 'w')\n",
    "     pstd.write(\"PB_TCV_451045\\n\")\n",
    "     pstd.write(str(npart)+'\\n')\n",
    "     \n",
    "     Tst = open(save_path+'TStart_'+str(test_frame)+'.gro', 'w')\n",
    "     Tst.write(\"PB_TCV_451045\\n\")\n",
    "     Tst.write(str(npart)+\"\\n\")\n",
    "    \n",
    "     tstd = open(save_path+\"TStart_\"+str(test_frame)+'.dat', 'w')\n",
    "     tstd.write(\"PB_TCV_451045\\n\")\n",
    "     tstd.write(str(npart)+'\\n')     \n",
    "\n",
    "  identities, shiftx, img_nmer, names = mer_identity(inp[0])    \n",
    "  chemistry += identities\n",
    "  chain_names += names\n",
    "  \n",
    "  # Get a prediction of the trained model \n",
    "  pred = model.predict(inp)\n",
    "  \n",
    "  # Reverse the normalization \n",
    "  pred[0] += 1\n",
    "  pred[0] /= 2.\n",
    "  pred[0] *= 0.1711*2\n",
    "  pred[0] += -0.1711  \n",
    "  \n",
    "  c = 0\n",
    " \n",
    "  for ii in range(img_nmer):       \n",
    "       if identities[ii] == 0: dtseg,merlen,masses = dtseg_cis,merlen_cis,masses_cis\n",
    "       elif identities[ii] == 1: dtseg,merlen,masses = dtseg_trans,merlen_trans,masses_trans\n",
    "       elif identities[ii] == 2: dtseg,merlen,masses = dtseg_vinyl,merlen_vinyl,masses_vinyl\n",
    "       \n",
    "       P_bv=np.zeros([dtseg,3],dtype=np.float64)\n",
    "       T_bv=np.zeros([dtseg,3],dtype=np.float64)\n",
    "\n",
    "       iosx=float(inp[0][c+shiftx+1,0])\n",
    "       iosy=float(inp[0][c+shiftx+1,1])\n",
    "       iosz=float(inp[0][c+shiftx+1,2])\n",
    "       \n",
    "       j=0 \n",
    "       i = ua_idx(shiftx,c,j)\n",
    "       P_bv[j]=[float(pred[0][i,0]),float(pred[0][i,1]),float(pred[0][i,2])] \n",
    "       T_bv[j]=[float(tar[i,0]),float(tar[i,1]),float(tar[i,2])] \n",
    "\n",
    "       j=1 \n",
    "       i +=1\n",
    "       P_bv[j]=[float(pred[0][i,0]),float(pred[0][i,1]),float(pred[0][i,2])] \n",
    "       T_bv[j]=[float(tar[i,0]),float(tar[i,1]),float(tar[i,2])] \n",
    "       \n",
    "       j=2 \n",
    "       i +=1\n",
    "       P_bv[j]=[float(pred[0][i,0]),float(pred[0][i,1]),float(pred[0][i,2])] \n",
    "       T_bv[j]=[float(tar[i,0]),float(tar[i,1]),float(tar[i,2])] \n",
    "        \n",
    "       j=3 \n",
    "       i +=1\n",
    "       P_bv[j]=[float(pred[0][i,0]),float(pred[0][i,1]),float(pred[0][i,2])] \n",
    "       T_bv[j]=[float(tar[i,0]),float(tar[i,1]),float(tar[i,2])] \n",
    "        \n",
    "       c += dtseg  \n",
    "       if(identities[ii]==0): \n",
    "              cis_d(P_bv,masses,iosx,iosy,iosz,pb0,nmer_count,Pcoords,chemistry,PartIndx)\n",
    "              cis_d(T_bv,masses,iosx,iosy,iosz,tb0,nmer_count,Tcoords,chemistry,PartIndx)\n",
    "              PartIndx += merlen \n",
    "       elif(identities[ii]==1): \n",
    "              trans_d(P_bv,masses,iosx,iosy,iosz,pb0,nmer_count,Pcoords,chemistry,PartIndx)\n",
    "              trans_d(T_bv,masses,iosx,iosy,iosz,tb0,nmer_count,Tcoords,chemistry,PartIndx) \n",
    "              PartIndx += merlen \n",
    "       elif(identities[ii]==2): \n",
    "              vinyl_d(P_bv,masses,iosx,iosy,iosz,pb0,nmer_count,Pcoords,chemistry,PartIndx)\n",
    "              vinyl_d(T_bv,masses,iosx,iosy,iosz,tb0,nmer_count,Tcoords,chemistry,PartIndx)\n",
    "              PartIndx += merlen \n",
    "                 \n",
    "       nmer_count += 1\n",
    "  if len(chemistry) == nmer :\n",
    "    for ii in range(Pcoords.shape[0]-1):\n",
    "        while(Pcoords[ii+1][0]-Pcoords[ii][0]<-hLXX): Pcoords[ii+1][0]+=LXX\n",
    "        while(Pcoords[ii+1][0]-Pcoords[ii][0]>hLXX): Pcoords[ii+1][0]-=LXX\n",
    "        while(Pcoords[ii+1][1]-Pcoords[ii][1]<-hLYY): Pcoords[ii+1][1]+=LYY\n",
    "        while(Pcoords[ii+1][1]-Pcoords[ii][1]>hLYY): Pcoords[ii+1][1]-=LYY\n",
    "        while(Pcoords[ii+1][2]-Pcoords[ii][2]<-hLZZ): Pcoords[ii+1][2]+=LZZ\n",
    "        while(Pcoords[ii+1][2]-Pcoords[ii][2]>hLZZ): Pcoords[ii+1][2]-=LZZ       \n",
    "    for j in range(Pcoords.shape[0]):  \n",
    "       Pst.write('%5d%5s%5s%5s%8.3f%8.3f%8.3f  0.0000  0.0000  0.0000\\n'%((pdimg+1,'PB',chain_names[j],str(j+1+pdimg*chainlen)[-5:],Pcoords[j][0],Pcoords[j][1],Pcoords[j][2]))) \n",
    "       print(chain_names[j],Pcoords[j][0],Pcoords[j][1],Pcoords[j][2], file=pstd)   \n",
    "       Tst.write('%5d%5s%5s%5s%8.3f%8.3f%8.3f  0.0000  0.0000  0.0000\\n'%((pdimg+1,'PB',chain_names[j],str(j+1+pdimg*chainlen)[-5:],Tcoords[j][0],Tcoords[j][1],Tcoords[j][2]))) \n",
    "       print(chain_names[j],Tcoords[j][0],Tcoords[j][1],Tcoords[j][2], file=tstd)  \n",
    "    pdimg+=1\n",
    "    chemistry = []\n",
    "    chain_names = []\n",
    "    pb0=np.zeros([nmer,3],dtype=np.float64)\n",
    "    tb0=np.zeros([nmer,3],dtype=np.float64)\n",
    "    nmer_count = 0\n",
    "    PartIndx = 0\n",
    "   \n",
    "    if (pdimg%nchain) == 0:  \n",
    "        nframes+=1\n",
    "        pdimg=0\n",
    "        print(nframes)\n",
    "        Pst.write('%10.5f%10.5f%10.5f\\n'%((LXX , LYY , LZZ)))\n",
    "        Pst.close\n",
    "        pstd.close\n",
    "        Tst.write('%10.5f%10.5f%10.5f\\n'%((LXX , LYY , LZZ)))\n",
    "        Tst.close\n",
    "        tstd.close\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9c30da",
   "metadata": {},
   "source": [
    "### Prediction of an atomistic configuration from a given CG configuration <span id='p'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6f0db1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./tmp_c18/cp-0700.ckpt\"\n",
    "model.load_weights(checkpoint_path)\n",
    "create_chains(test_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0369a61",
   "metadata": {},
   "source": [
    "# Visualize the results <span id='q'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0e1ede",
   "metadata": {},
   "source": [
    "### Generate the distribution plots for bond lengths, bond angles and dihedral angles <span id='r'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "870652f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Bond lenghts combinations:  18\n",
      "Bond angles combinations:  27\n",
      "Dihedral angles combinations:  42\n",
      "Bond lenghts combinations:  18\n",
      "Bond angles combinations:  27\n",
      "Dihedral angles combinations:  42\n",
      "4.125962018966675\n"
     ]
    }
   ],
   "source": [
    "generate_distribution_plots(test_frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
